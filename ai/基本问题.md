权重衰减

参数大小和过拟合的关系：
1. 小参数+大噪音
	1. ![](附件/Pasted%20image%2020230424084001.png)
	2. 效果
		1. 无正则项![](附件/Pasted%20image%2020230424084341.png)
		2. 有正则项![](附件/Pasted%20image%2020230424084350.png)
	3. 疑问
		1. 无正则项时，训练损失可以降低到小于 $10^{-4}$，有的时候则只有大于 1
			1. 学习能力过大，即每次参数更新过多![](附件/Pasted%20image%2020230424091847.png)
		2. 为啥训练损失大？ #AI遗留 
			1. 正常现象
			2. 因为噪音太大，即使拟合噪音构成的损失也会很大
2. 大参数+小噪音
	1. ![](附件/Pasted%20image%2020230424092611.png)
	2. 结果
		1. 无正则项![](附件/Pasted%20image%2020230424092637.png)
		2. 有正则项
			1. $\lambda=3$![](附件/Pasted%20image%2020230424092812.png)
			2. $\lambda=10$![](附件/Pasted%20image%2020230424092833.png)
			3. $\lambda=50$![](附件/Pasted%20image%2020230424092850.png)
	3. 疑问：大参数+小噪音为什么会过拟合---数据量小，迭代次数多，一定会过拟合
	4. 结论：$\lambda$ 小的时候，是学习太慢
3. 大参数+大噪音
	1. ![](附件/Pasted%20image%2020230424094109.png)
	2. 结果
		1. 无正则项![](附件/Pasted%20image%2020230424094132.png)
		2. 有正则项![](附件/Pasted%20image%2020230424094154.png)
	3. 结论：正则项越大，训练损失会趋于不动，测试损失一直保持不动
4. 遗留
	1. 为什么参数小，噪音大的时候，数据没有被噪音覆盖
	2. 为什么大参数，大噪音学习效果奇差（难道是因为 x 太小？）(梯度爆炸，一档程度上梯度和输入有关。但是也不深啊)
		1. 验证：x 太大，损失函数会溢出


---
dropout
梯度消失   梯度和 w 参数有关
梯度爆炸
权重初始化

没学习好，$\lambda$ 占比多了往圆心缩小了 